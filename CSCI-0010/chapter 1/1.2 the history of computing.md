# 1.2 The History of Computing
hardware and software history are discussed separately because they had different impacts on computer system design 

## A Brief History of Computing Hardware
devices assisting humans in computations are rooted in ancient history

### Early History
Stonehenge: a collection of monoliths in Great Britain thought to be an early temple, cemetery, calendar or astrological calculator
- Neolithic stone structure in the Salisbury Plain in England first erected beginning in 2180 BCE

_abacus_ (16th century): recorded numeric values and enabled more complex arithmetic 
gear-driven mechanical machines (mid 17th century): designed by French mathematician Blaise Pascal, performed whole-number addition and subtraction
- improved upon by Gottfried Wilhelm von Leibniz, who implemented all four whole-number operations (was not very reliable)

_Jacquard's loom_ (late 18th century): developed by Joseph Jacquard to weave colored cloth based on punched cards
- not a computing device but the first implementation of card input

_analytical engine_: theory conceptualized by British mathematician Charles Babbage
- first design to include memory (eliminated the need for re-entering intermediate values)
- leveraged number & mechanical step inputs with punched cards

Ada Augusta, Countess of Lovelace: daughter of Lord Byron and extended the analytical engine
- thought to be the first programmer
- described series of repeatable instructions 

mechanical adding machine (20th century): produced and sold by William Burroughs 
electro-mechanical tabulator: invented by Dr. Herman Hollerith, read information from punched cards
- revolutionized how the US census was taken
- Hollerith later created IBM

_Turing machine_ (1936): an abstract mathematical model invented by British mathematician Alan M. Turing
- became the foundation of modern computing
- Turing Award: the most prestigious award given in computer science

1-bit binary adder (1937): a device using relays to add binary digits, constructed by George Stibitz
symbolic logic (1938): paper on implementation with relays by Claude E. Shannon

mechanical binary computer (1938): first programmable machine developed by Konrad Zuse
Colossus (1943): first all-programmable electronic digital computer built in London by Thomas Flowers

IBM Automatic Sequence Controlled Calculator (_Harvard Mark I_) (1944)
ENIAC (1946) & EDVAC (1950): giant World War II-era computers worked on by John von Neumann
UNIVAC I (1951): first commercial computer used by the US Bureau of the Census
- used to predict the outcome of a presidential election

### Counting Precedes Writing 
7500 BCE farmers shaped clay counters 
- cones meant small measures of grain, spheres for large measures of grain, and a cylinder for an animal
- 8000 tokens have been found around Palestine, Anatolia, Syria, Mesopotamia & Iran

3500 BCE stamped clay balls were used as envelopes to hold tokens
3300 - 3200 BCE just used the impressions of tokens onto clay
3100 BCE styluses were used to draw tokens rather than 3D shapes 
writing was derived from counting as abstract numerals were created to represent goods

### First Generation (1951 - 1959)
commercial computers within the first generation used _vacuum tubes_ to store information
- generated too much heat & were unreliable 
- required heavy-duty air conditioning, large spaces & frequent maintenance 

_magnetic drum_: a memory device that rotated under a read/write head
the primary input device was a card reader that accepted a hole punched IBM card
- _magnetic tape drives_ are sequential storage units that increased in popularity because they were faster than card readers 

the primary output device was a punched card or a line printer 

_auxiliary storage devices_: external storage that isn't computer memory
_peripheral devices_: input devices, output devices, and auxiliary storage devices

### Second Generation (1959 - 1965)
_transistors_ replaced the vacuum tube
- faster, smaller, cheaper, durable
- developed by Nobel Prize winners John Bardeen, Walter H. Brattain, and William B. Shockley

_magnetic cores_: the second generation of memory capable of storing one bit in strung together in cells
- information was instantaneously available because the device was motionless & electronically based

_magnetic disk_: faster than magnetic tape because information could be referenced by location on the disk
- data organized into unique _addresses_ 
- read/write heads can be directed to a location on the disk where information is stored without accessing all of the previous information

### Third Generation (1965 - 1971)
_circuit boards_: hand printed sheets with transistors & computer components
_integrated circuits_ (ICs): silicon sheets containing transistors, components, and connections
- much smaller, cheaper, faster, and reliable than printed boards

_Moore's Law_: Gordon Moore (co-founder of Intel) noted the number of circuits within a single IC doubled each year
transistors were also used in memory boards, but auxiliary storage was still needed because transistors were _volatile_ and lost information when energy was lost
_terminal_: input/output with a keyboard and screen provided direct access to the computer and an immediate response 

### Fourth Generation (1971 - Present)
_Large-scale integration_: moved from a thousand transistors to entire microcomputers on a single chip 
- _personal computers_ (PC) are cheap enough for the average consumer
- Apple, Tandy/Radio Shack, Atari, Commodore, Sun, IBM, Remington, Rand, NCR, DEC, Hewlett-Packard, Control Data, and Burroughs enter the commercial market

Steve Wozniak and Steve Jobs create the Apple Computer, marketing a personal computer kit 
(1981) IBM PC was introduced
- Dell & Compaq create IBM compatible PCs

(1984) Apple releases Macintosh

_workstations_: business use computers networked together 
workstations were enhanced by RISC (reduced-instruction-set computer); computers were built to understand a native _machine language_
- IBM 370/168 implemented 200 specialized instructions
- (1987) Sun Microsystems implemented a _UNIX_ workstation with a RISC chip

Moore's law was modified to say chip power doubled or price halved every 18 months, with each generation of computer hardware more powerful, smaller, and cheaper than the previous

### Parallel Computing 
_parallel architectures_ rely on interconnected CPUs
- increase speed of execution but requires programmers to rewrite software initially designed for sequential machines
- _SIMD_ (single-instruction, multiple-data-stream): a given step in a program is separated and executed simultaneously
- _MIMD_ (multiple-instruction, multiple-data-stream): programs are separated and executed simultaneously

there are two main types of parallel architectures
1. all processors share the same memory
2. processors have local memory but are internally networked

### Networking
(1973) Robert Metcalfe & David Boggs invent the _Ethernet_, which set protocols and used a coaxial cable to allow separate machines to communicate
- (1979) DEC, Intel, and Xerox establish Ethernet as the new standard
- (1985) Intel releases an advanced chip capable of handling networking on personal computers

(1989) Novell's Netware connected PCs into a  _file server_
- enabled central control while giving individual machines autonomy 
- _LANs_ (local area networks): networked workstations or PCs

(1960s) ARPANET: government sponsored network with 11 nodes based in LA and Boston
- used _packet switching_ to allow messages to share lines
- (1990s) evolved into the _Internet_

The Internet is composed of several global networks that communicate through TCP/IP (Transmission Control Protocol/Internet Protocol)
- did not fully supplant Ethernet, which allowed for easy local connections in office and PCs

### Cloud Computing
_data center_: a third-party business that provides and configures the necessary hardware to maximize computing power for a business 
- resolves hardware issues regarding maintenance & upgrading
- often took days to establish communication between a server and computer needed by the business
- evolved into _cloud computing_, use virtual computer resources rather than physical devices

## A Brief History of Computing Software
hardware is directed by software, which has evolved over time into modern computing systems

### First-Generation Software (1951 - 1959)
_machine language_: instructions embedded into the electrical circuitry of a computer
- written in _binary_
- programmers needed to remember the sequence of numbers, which was tedious and error-prone

_assembly language_ : mnemonic codes that represented _machine language_ instructions
- _translators_: converted assembly into machine code
  - _assembler_: reads program instructions written in assembly and translates them into the machine language equivalent
- not human readable but much easier to use

### Second-Generation Software (1959 - 1965)
_high-level languages_: allowed programmers to write more English-like statements rather than individual machine instructions
- FORTRAN: designed to solve numerical applications, became increasingly updated and complex
- COBOL: designed to solve business applications, didn't change much
- Lisp (_Scheme_): typically used for AI applications and research but was not widely used at the time

_compiler_: translates high-level languages into machine instructions while enforcing the language's syntax
- meant more languages allowed programs to run on several computers as long as the appropriate compiler was used

_system programmers_: made tools to make programming easier for
- wrote assemblers and compilers

_application programmers_: used tools to write programs

### Third-Generation Software (1965 - 1971)
initially computer operators needed to prepare the next job
- _operating systems_ (OS): automated computer resources

utility programs handled common tasks
- _loaders_: loaded programs into memory
- _linkers_: combined large programs together

_systems software_: composed for the OS, utility programs, and language translators (assemblers and compilers)
_time sharing_: enabled different users at terminals to communicate with a single computer simultaneously
- the OS organized and scheduled jobs to service multiple users

system programmers began writing software packages that nonprogrammers could readily use
- ex) Statistical Package for the Social Sciences (SPSS): written in FORTRAN, allowed users to describe data & statistics that could be processed by the computer 

### Fourth Generation (1981 - 1989)
_structured programming_: structured programming techniques
- first implemented as Pascal and Modula-2
- BASIC was better refined (first scene in generation three)
- C & C++ allowed programmers to access low-level statements in a high-level program & quickly became the industry standard

more powerful operating systems were being created
- UNIX: developed by AT&T, became the university standard
- PC-DOS/MS-DOS developed for IBM (compatible) PCs
- Apple exploited research at Xerox PARC to create a graphical interface with a mouse

application software packages were sold on stores
introduced spreadsheets, word processors, and database management systems
- Lotus 1-2-3: the first commercially successful spreadsheet that enabled users to enter & analyze data
- WordPerfect: first word processor
- dBase IV: allowed users to store, organize & retrieve data

### Fifth Generation (1990 - Present)
characterized by Microsoft, object-oriented programming, and the World Wide Web
Windows and Microsoft Word quickly popularized
_office suites_: bundles of word processors, spreadsheet programs, database programs, and application programs
_object-oriented design_: based on the hierarchy of data objects (not tasks)
- designed by Sun Microsystems
- rivaled C++

(1990): British researcher Tim Berners-Lee at CERN physics in Geneva, Switzerland created protocols for a document center dubbed the _World Wide Web_
- HTML: language to format documents
- _browser_: allowed users to access information from websites
- (1993) Marc Andreesen & Eric Bina release Mosaic, the first graphical browser 

The most popular browsers became Netscape Navigator (derived from Mosaic) & Microsoft Internet Explorer (IE)
- IE (eventually replaced by _Edge_) as bundled together with Windows
- (2001) the US government required Microsoft to be more transparent

(1998): America Online purchased and eventually discontinued Netscape
(2004): Firefox & Safari by Apple was released
(2008): Google releases _Chrome_

The Internet had existed for decades prior but the World Wide Web popularized user-generated and user-edited content
_embedded system_: integrated circuits or chips regulate and run common-place technology not considered computers in the truest sense
